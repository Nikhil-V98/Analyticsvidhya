{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>author</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39467</td>\n",
       "      <td>rayinstirling</td>\n",
       "      <td>Today I'm working on my &amp;quot;Quirky Q&amp;quot; c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30154</td>\n",
       "      <td>DirtyRose17</td>\n",
       "      <td>@ShannonElizab dont ya know? people love the h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16767</td>\n",
       "      <td>yoliemichelle</td>\n",
       "      <td>ughhh rejected from the 09 mediation program. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9334</td>\n",
       "      <td>jayamelwani</td>\n",
       "      <td>@petewentz im so jealous. i want an octo drive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61178</td>\n",
       "      <td>aliisanoun</td>\n",
       "      <td>I remember all the hype around this movie when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID         author                                             Review  \\\n",
       "0  39467  rayinstirling  Today I'm working on my &quot;Quirky Q&quot; c...   \n",
       "1  30154    DirtyRose17  @ShannonElizab dont ya know? people love the h...   \n",
       "2  16767  yoliemichelle  ughhh rejected from the 09 mediation program. ...   \n",
       "3   9334    jayamelwani     @petewentz im so jealous. i want an octo drive   \n",
       "4  61178     aliisanoun  I remember all the hype around this movie when...   \n",
       "\n",
       "   Sentiment  \n",
       "0          2  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "test = df_test.copy()\n",
    "\n",
    "train.drop(['ID','author'],axis =1,inplace=True)\n",
    "test.drop(['ID','author'],axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b8016eacfd4fdfa7aa77cd16e103c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9a2569a38e46cc988b25303b5dfffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d82c46d9f76450ca243b23f9f0dbbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nik\\Documents\\GitHub\\Hackathons\\Machinehack\\Sentiment_Analysis\\NLP.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nik/Documents/GitHub/Hackathons/Machinehack/Sentiment_Analysis/NLP.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dls_lm \u001b[39m=\u001b[39m DataBlock(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nik/Documents/GitHub/Hackathons/Machinehack/Sentiment_Analysis/NLP.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     blocks\u001b[39m=\u001b[39;49mTextBlock\u001b[39m.\u001b[39;49mfrom_df(\u001b[39m'\u001b[39;49m\u001b[39mReview\u001b[39;49m\u001b[39m'\u001b[39;49m, is_lm\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nik/Documents/GitHub/Hackathons/Machinehack/Sentiment_Analysis/NLP.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     get_x\u001b[39m=\u001b[39;49mColReader(\u001b[39m'\u001b[39;49m\u001b[39mReview\u001b[39;49m\u001b[39m'\u001b[39;49m), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nik/Documents/GitHub/Hackathons/Machinehack/Sentiment_Analysis/NLP.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     splitter\u001b[39m=\u001b[39;49mRandomSplitter(\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nik/Documents/GitHub/Hackathons/Machinehack/Sentiment_Analysis/NLP.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\u001b[39m.\u001b[39;49mdataloaders(train, bs\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, seq_len\u001b[39m=\u001b[39;49m\u001b[39m72\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\block.py:155\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[1;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataloaders\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    150\u001b[0m     source, \u001b[39m# The data source\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     path:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Data source and default `Learner` path \u001b[39;00m\n\u001b[0;32m    152\u001b[0m     verbose:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m# Show verbose messages\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataLoaders:\n\u001b[1;32m--> 155\u001b[0m     dsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets(source, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    156\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: verbose}\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m dsets\u001b[39m.\u001b[39mdataloaders(path\u001b[39m=\u001b[39mpath, after_item\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_tfms, after_batch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_tfms, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\block.py:147\u001b[0m, in \u001b[0;36mDataBlock.datasets\u001b[1;34m(self, source, verbose)\u001b[0m\n\u001b[0;32m    145\u001b[0m splits \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplitter \u001b[39mor\u001b[39;00m RandomSplitter())(items)\n\u001b[0;32m    146\u001b[0m pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(splits)\u001b[39m}\u001b[39;00m\u001b[39m datasets of sizes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(s)) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m splits])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[1;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m Datasets(items, tfms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_type_tfms(), splits\u001b[39m=\u001b[39;49msplits, dl_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdl_type, n_inp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_inp, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\core.py:451\u001b[0m, in \u001b[0;36mDatasets.__init__\u001b[1;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    443\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     tfms:\u001b[39mlist\u001b[39m\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    449\u001b[0m ):\n\u001b[0;32m    450\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[0;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\core.py:451\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    443\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     tfms:\u001b[39mlist\u001b[39m\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    449\u001b[0m ):\n\u001b[0;32m    450\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[0;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[1;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\core.py:365\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[1;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m do_setup:\n\u001b[0;32m    364\u001b[0m     pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSetting up \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[1;32m--> 365\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(train_setup\u001b[39m=\u001b[39;49mtrain_setup)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\data\\core.py:386\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[1;34m(self, train_setup)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    384\u001b[0m     train_setup:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39m# Apply `Transform`(s) only on training `DataLoader`\u001b[39;00m\n\u001b[0;32m    385\u001b[0m ):\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfms\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m, train_setup)\n\u001b[0;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    388\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\transform.py:200\u001b[0m, in \u001b[0;36mPipeline.setup\u001b[1;34m(self, items, train_setup)\u001b[0m\n\u001b[0;32m    198\u001b[0m tfms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs[:]\n\u001b[0;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mclear()\n\u001b[1;32m--> 200\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tfms: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(t,items, train_setup)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\transform.py:204\u001b[0m, in \u001b[0;36mPipeline.add\u001b[1;34m(self, ts, items, train_setup)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(\u001b[39mself\u001b[39m,ts, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, train_setup\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_listy(ts): ts\u001b[39m=\u001b[39m[ts]\n\u001b[1;32m--> 204\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ts: t\u001b[39m.\u001b[39;49msetup(items, train_setup)\n\u001b[0;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mts\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39msorted(key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\transform.py:87\u001b[0m, in \u001b[0;36mTransform.setup\u001b[1;34m(self, items, train_setup)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, train_setup\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     86\u001b[0m     train_setup \u001b[39m=\u001b[39m train_setup \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_setup \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_setup\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetups(\u001b[39mgetattr\u001b[39;49m(items, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, items) \u001b[39mif\u001b[39;49;00m train_setup \u001b[39melse\u001b[39;49;00m items)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst)\n\u001b[0;32m    119\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\text\\core.py:289\u001b[0m, in \u001b[0;36mTokenizer.setups\u001b[1;34m(self, dsets)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetups\u001b[39m(\u001b[39mself\u001b[39m, dsets):\n\u001b[0;32m    288\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dsets\u001b[39m.\u001b[39mitems, pd\u001b[39m.\u001b[39mDataFrame): \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     dsets\u001b[39m.\u001b[39mitems,count \u001b[39m=\u001b[39m tokenize_df(dsets\u001b[39m.\u001b[39mitems, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_cols, rules\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrules, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39m=\u001b[39m count\n\u001b[0;32m    291\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlengths \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlengths \u001b[39m=\u001b[39m dsets\u001b[39m.\u001b[39mitems[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtok_text_col\u001b[39m}\u001b[39;00m\u001b[39m_length\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\text\\core.py:221\u001b[0m, in \u001b[0;36mtokenize_df\u001b[1;34m(df, text_cols, n_workers, rules, mark_fields, tok, tok_text_col)\u001b[0m\n\u001b[0;32m    219\u001b[0m rules \u001b[39m=\u001b[39m L(ifnone(rules, defaults\u001b[39m.\u001b[39mtext_proc_rules\u001b[39m.\u001b[39mcopy()))\n\u001b[0;32m    220\u001b[0m texts \u001b[39m=\u001b[39m _join_texts(df[text_cols], mark_fields\u001b[39m=\u001b[39mmark_fields)\n\u001b[1;32m--> 221\u001b[0m outputs \u001b[39m=\u001b[39m L(parallel_tokenize(texts, tok, rules, n_workers\u001b[39m=\u001b[39;49mn_workers)\n\u001b[0;32m    222\u001b[0m            )\u001b[39m.\u001b[39msorted()\u001b[39m.\u001b[39mitemgot(\u001b[39m1\u001b[39m)\n\u001b[0;32m    224\u001b[0m other_cols \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns[\u001b[39m~\u001b[39mdf\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39misin(text_cols)]\n\u001b[0;32m    225\u001b[0m res \u001b[39m=\u001b[39m df[other_cols]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[1;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\foundation.py:106\u001b[0m, in \u001b[0;36mL.__init__\u001b[1;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, items\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39mrest, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m (use_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_array(items):\n\u001b[1;32m--> 106\u001b[0m         items \u001b[39m=\u001b[39m listify(items, \u001b[39m*\u001b[39;49mrest, use_list\u001b[39m=\u001b[39;49muse_list, match\u001b[39m=\u001b[39;49mmatch)\n\u001b[0;32m    107\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(items)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\basics.py:66\u001b[0m, in \u001b[0;36mlistify\u001b[1;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mlist\u001b[39m): res \u001b[39m=\u001b[39m o\n\u001b[0;32m     65\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m is_array(o): res \u001b[39m=\u001b[39m [o]\n\u001b[1;32m---> 66\u001b[0m \u001b[39melif\u001b[39;00m is_iter(o): res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(o)\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m: res \u001b[39m=\u001b[39m [o]\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m match \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastcore\\parallel.py:145\u001b[0m, in \u001b[0;36mparallel_gen\u001b[1;34m(cls, items, n_workers, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parallelable(\u001b[39m'\u001b[39m\u001b[39mn_workers\u001b[39m\u001b[39m'\u001b[39m, n_workers): n_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m n_workers\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)(items)))\n\u001b[0;32m    146\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    147\u001b[0m batches \u001b[39m=\u001b[39m L(chunked(items, n_chunks\u001b[39m=\u001b[39mn_workers))\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\text\\core.py:138\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m (L(o)\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_f) \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtok(maps(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrules, batch)))\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastai\\text\\core.py:124\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, items):\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m (L(doc)\u001b[39m.\u001b[39mattrgot(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipe(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,items), batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_sz))\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1583\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1581\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[0;32m   1582\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1583\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[0;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1580\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1577\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiprocessing_pipe(texts, pipes, n_process, batch_size)\n\u001b[0;32m   1578\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1579\u001b[0m     \u001b[39m# if n_process == 1, no processes are forked.\u001b[39;00m\n\u001b[1;32m-> 1580\u001b[0m     docs \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts)\n\u001b[0;32m   1581\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[0;32m   1582\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1099\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m doc_like\n\u001b[0;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_doc(doc_like)\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1091\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length:\n\u001b[0;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1089\u001b[0m         Errors\u001b[39m.\u001b[39mE088\u001b[39m.\u001b[39mformat(length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(text), max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length)\n\u001b[0;32m   1090\u001b[0m     )\n\u001b[1;32m-> 1091\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(text)\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokenizer.pyx:155\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokenizer.pyx:191\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize_affixes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokenizer.pyx:395\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokenizer.pyx:473\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\vocab.pyx:160\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\vocab.pyx:197\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\lang\\lex_attrs.py:146\u001b[0m, in \u001b[0;36mlower\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlower\u001b[39m(string: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m string\u001b[39m.\u001b[39;49mlower()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_df('Review', is_lm=True),\n",
    "    get_x=ColReader('Review'), \n",
    "    splitter=RandomSplitter(0.1)\n",
    ").dataloaders(train, bs=128, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower casing: Converting a word to lower case (NLP -> nlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i  in range(train.shape[0]):\n",
    "    train['Review']=train['Review'][i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization: Splitting the sentence into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for i  in range(train.shape[0]):\n",
    "    words.append(nltk.word_tokenize(train['Review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different tokenizer which does not split at apostrophe\n",
    "words_1=[]\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "for i  in range(train.shape[0]):\n",
    "    words_1.append(TweetTokenizer().tokenize(train['Review'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words removal: Stop words are very commonly used words (a, an, the, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "788a82b91c0336814844834dbe028694862d9bc55d1fd4a8a9273fa14df8fc57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
