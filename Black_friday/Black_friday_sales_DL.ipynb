{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/Nikhil-V98/Analyticsvidhya/main/Black_friday/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Nikhil-V98/Analyticsvidhya/main/Black_friday/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0,inplace=True)\n",
    "train.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {'F':0, 'M':1}\n",
    "age_dict = {'0-17':17, '18-25':25, '26-35':35, '36-45':45, '46-50':50, '51-55':55, '55+':60}\n",
    "city_dict = {'A':0, 'B':1, 'C':2}\n",
    "stay_dict = {'0':0, '1':1, '2':2, '3':3, '4+':4}\n",
    "\n",
    "train['Gender'] = train['Gender'].map(gender_dict)\n",
    "test['Gender'] = test['Gender'].map(gender_dict)\n",
    "\n",
    "train['Age'] = train['Age'].map(age_dict)\n",
    "test['Age'] = test['Age'].map(age_dict)\n",
    "\n",
    "train['City_Category'] = train['City_Category'].map(city_dict)\n",
    "test['City_Category'] = test['City_Category'].map(city_dict)\n",
    "\n",
    "train['Stay_In_Current_City_Years'] = train['Stay_In_Current_City_Years'].map(stay_dict)\n",
    "test['Stay_In_Current_City_Years'] = test['Stay_In_Current_City_Years'].map(stay_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nik\\AppData\\Local\\Temp\\ipykernel_11348\\3452910973.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testRes['Product_ID'] = test['Product_ID']\n"
     ]
    }
   ],
   "source": [
    "testRes = test[['User_ID']]\n",
    "testRes['Product_ID'] = test['Product_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train['User_ID']=enc.fit_transform(train['User_ID'],)\n",
    "test['User_ID']=enc.transform(test['User_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scalar\n",
    "train['Product_ID'] = train['Product_ID'].str.replace('P00', '')\n",
    "test['Product_ID'] = test['Product_ID'].str.replace('P00', '')\n",
    "\n",
    "train['Product_ID'] = scaler.fit_transform(train['Product_ID'].values.reshape(-1, 1))\n",
    "test['Product_ID'] = scaler.transform(test['Product_ID'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding Product_IDs\n",
    "new_product_ids = list(set(pd.unique(test_data['product_id'])) - set(pd.unique(train_data['product_id'])))\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_data['product_id'] = le.fit_transform(train_data['product_id'])\n",
    "test_data.loc[test_data['product_id'].isin(new_product_ids), 'product_id'] = -1\n",
    "new_product_ids.append(-1)\n",
    "\n",
    "test_data.loc[~test_data['product_id'].isin(new_product_ids), 'product_id'] = le.transform(test_data.loc[~test_data['product_id'].isin(new_product_ids), 'product_id'])\n",
    "\n",
    "# Drop User ID and Product ID from test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = ['Gender', 'City_Category','Marital_Status']\n",
    "numerical_col = ['Age', 'Occupation', 'Stay_In_Current_City_Years', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_col:\n",
    "    train[col] = enc.fit_transform(train[col])\n",
    "    test[col] = enc.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_col:\n",
    "    train[col] = scaler.fit_transform(train[col].values.reshape(-1, 1))\n",
    "    test[col] = scaler.transform(test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train.drop(['Purchase'], axis=1)\n",
    "y = train[['Purchase']]\n",
    "X_test = test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(15, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)\n",
    "output = Dense(y.shape[1], activation='relu')(dense_layer_2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128,input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN_model.fit(X_train, y_train, epochs=50, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation=\"tanh\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 256)               3072      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,705\n",
      "Trainable params: 200,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13752/13752 [==============================] - 56s 4ms/step - loss: 25504058.0000 - val_loss: 22430708.0000\n",
      "Epoch 2/15\n",
      "13752/13752 [==============================] - 60s 4ms/step - loss: 21041052.0000 - val_loss: 21826564.0000\n",
      "Epoch 3/15\n",
      "13752/13752 [==============================] - 60s 4ms/step - loss: 20450688.0000 - val_loss: 20171306.0000\n",
      "Epoch 4/15\n",
      "13752/13752 [==============================] - 73s 5ms/step - loss: 19988454.0000 - val_loss: 19364350.0000\n",
      "Epoch 5/15\n",
      "13752/13752 [==============================] - 59s 4ms/step - loss: 18983780.0000 - val_loss: 18547648.0000\n",
      "Epoch 6/15\n",
      "13752/13752 [==============================] - 65s 5ms/step - loss: 18904586.0000 - val_loss: 18271030.0000\n",
      "Epoch 7/15\n",
      "13752/13752 [==============================] - 60s 4ms/step - loss: 18891806.0000 - val_loss: 18348964.0000\n",
      "Epoch 8/15\n",
      "13752/13752 [==============================] - 65s 5ms/step - loss: 18821872.0000 - val_loss: 18598696.0000\n",
      "Epoch 9/15\n",
      "13752/13752 [==============================] - 71s 5ms/step - loss: 18747162.0000 - val_loss: 19252208.0000\n",
      "Epoch 10/15\n",
      "13752/13752 [==============================] - 77s 6ms/step - loss: 18733434.0000 - val_loss: 18377596.0000\n",
      "Epoch 11/15\n",
      "13752/13752 [==============================] - 70s 5ms/step - loss: 18687684.0000 - val_loss: 18270842.0000\n",
      "Epoch 12/15\n",
      "13752/13752 [==============================] - 74s 5ms/step - loss: 18697574.0000 - val_loss: 18320976.0000\n",
      "Epoch 13/15\n",
      "13752/13752 [==============================] - 61s 4ms/step - loss: 18746322.0000 - val_loss: 21278442.0000\n",
      "Epoch 14/15\n",
      "13752/13752 [==============================] - 60s 4ms/step - loss: 18739536.0000 - val_loss: 19063870.0000\n",
      "Epoch 15/15\n",
      "13752/13752 [==============================] - 59s 4ms/step - loss: 18626802.0000 - val_loss: 18559784.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data = (X_val, y_val),epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300/7300 [==============================] - 18s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nik\\AppData\\Local\\Temp\\ipykernel_11348\\797390692.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testRes['Purchase'] = yPreds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P00128942</td>\n",
       "      <td>14072.770508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000009</td>\n",
       "      <td>P00113442</td>\n",
       "      <td>10907.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00288442</td>\n",
       "      <td>7184.265137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00145342</td>\n",
       "      <td>7867.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011</td>\n",
       "      <td>P00053842</td>\n",
       "      <td>8827.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID      Purchase\n",
       "0  1000004  P00128942  14072.770508\n",
       "1  1000009  P00113442  10907.976562\n",
       "2  1000010  P00288442   7184.265137\n",
       "3  1000010  P00145342   7867.417969\n",
       "4  1000011  P00053842   8827.187500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPreds = model.predict(X_test)\n",
    "testRes['Purchase'] = yPreds\n",
    "submission = testRes[['User_ID', 'Product_ID', 'Purchase']]\n",
    "\n",
    "submission.columns = ['User_ID', 'Product_ID', 'Purchase']\n",
    "submission.to_csv('submission_V2_DL.csv', index = False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "788a82b91c0336814844834dbe028694862d9bc55d1fd4a8a9273fa14df8fc57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
